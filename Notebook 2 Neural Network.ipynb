{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f9fad-1558-4b43-b1a3-0c47ac7ccd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372079a8-4308-4856-9174-bddeba7b2fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train.shape, test.shape, train.isnull().values.any(), test.isnull().values.any(), train.duplicated().sum(), test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0391a7b-1ebd-408c-a01f-8d691c2b21b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14666f1c-2d74-4bfb-8ae6-350715bc67c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d3a94e-62d0-4075-b271-5b4140ec91c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Response.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5c4d0-eb30-4cae-8ae7-8d3c97e6545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da948a-2b76-41f5-b597-97f7d8b3fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314c0ca9-1e81-4887-820c-a410f9cfdad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['Driving_License'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99dd826-e793-4717-ae00-8a6af4e3f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_info = {\n",
    "    'feature': [],\n",
    "    'dtype': [],\n",
    "    'unique_val': [],\n",
    "    }\n",
    "\n",
    "for col in train.columns:\n",
    "    feature_info['feature'].append(col)\n",
    "    feature_info['dtype'].append(train[col].dtype)\n",
    "    feature_info['unique_val'].append(len(train[col].unique()))\n",
    "\n",
    "features = pd.DataFrame(feature_info)\n",
    "features.set_index('feature', inplace=True)\n",
    "features = features.sort_values(by='unique_val', ascending=False)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c57cf8-88cf-4a13-a67e-d8974efa7f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems to be nominal; highly problematic due to 54 unique values\n",
    "train.drop(columns=['Region_Code'], inplace=True)\n",
    "# Seems to be nominal; highly problematic due to 152 unique values\n",
    "train.drop(columns=['Policy_Sales_Channel'], inplace=True)\n",
    "# nominal feature\n",
    "train.Previously_Insured = train.Previously_Insured.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32bd382-5aa9-4246-aabb-f3b0b1b7637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebalanced dataset sampling\n",
    "train_1 = train[train.Response==1]\n",
    "train_0 = train[train.Response==0].sample(train_1.shape[0], random_state=666)\n",
    "df_train = pd.concat([train_0, train_1])\n",
    "df_train.Response.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9670ae57-0114-4437-8244-77b4b1962412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf14c24d-22a8-4a85-93c5-77f7debf52fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# train/test split\n",
    "y = df_train['Response']\n",
    "X = df_train.drop('Response', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.19, random_state=0, stratify=df_train['Response'])\n",
    "df_train = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafe9af2-1898-4feb-8180-b3ec3199150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbcf812-f2eb-4ffb-9daa-434bd2e7cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8f2c5a-7ae0-4b4f-b4c4-d56c69f40845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu, chi2_contingency\n",
    "\n",
    "# numeric features testing\n",
    "for feature in X_train.select_dtypes(exclude='object').columns:\n",
    "    group_0 = df_train[df_train['Response']==0][feature]\n",
    "    group_1 = df_train[df_train['Response']==1][feature]\n",
    "    stat, p = mannwhitneyu(group_0, group_1, alternative='two-sided')\n",
    "    if p > 0.05:\n",
    "        print('Feature {} is statistically insignificant'.format(feature))\n",
    "        \n",
    "# nominal features testing\n",
    "for feature in X_train.select_dtypes(include='object').columns:\n",
    "    contingency_table = pd.crosstab(df_train[feature], df_train['Response'])\n",
    "    chi2_stat, p_val, dof, expected = chi2_contingency(contingency_table)\n",
    "    if p > 0.05:\n",
    "        print('Feature {} is statistically insignificant'.format(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4d3731-d835-4cb7-a0f9-e1849f4bf42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "prep = make_column_transformer((StandardScaler(), X_train.select_dtypes(include='float64').columns), \n",
    "                               (MinMaxScaler(), X_train.select_dtypes(include='int64').columns),\n",
    "                               (OneHotEncoder(drop='first'), X_train.select_dtypes(include='object').columns))\n",
    "\n",
    "X_train_transformed = prep.fit_transform(X_train)\n",
    "X_train_transformed = pd.DataFrame(X_train_transformed)\n",
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d147a58-6ae5-4360-b6f5-7bf1ffabef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935b061-f053-47d7-a33a-d1d6a5edcf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network architecture\n",
    "model = Sequential([\n",
    "    Input(shape=(8,)),  # Define the input shape here\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f6ed9e-679c-418e-821b-188d6e0a7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# compilation\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0000001)\n",
    "\n",
    "# backpropagation\n",
    "history = model.fit(\n",
    "    X_train_transformed, y_train,\n",
    "    epochs=25,\n",
    "    batch_size=1024,  \n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb5cce-330d-4db3-ba16-a88f750be87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = model.predict(pd.DataFrame(prep.fit_transform(X_test)), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f3f1f-bd1c-439f-b50f-8b5f117040d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, np.where(y_pred>0.5,1,0))\n",
    "\n",
    "TP = cm[1,1]\n",
    "TN = cm[0,0]\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]\n",
    "\n",
    "print('Sensitivity')\n",
    "print('When the acutal value is positive, how often is the prediction correct?')\n",
    "print('sensitivity: {}\\n'.format(round(TP/float(TP + FN), 3)))\n",
    "print('Specificity')\n",
    "print('When the acutal value is negative, how often is the prediction correct?')\n",
    "print('specificity: {}'.format(round(TN/float(TN + FP), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725ecebf-b0ec-4f49-8a50-1f7326e8804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Define labels for the confusion matrix\n",
    "labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], \n",
    "            yticklabels=['Actual 0', 'Actual 1'], cbar=False)\n",
    "plt.title('Confusion Matrix', fontsize=24)\n",
    "plt.xlabel('Predicted Label', fontsize=20)\n",
    "plt.ylabel('True Label', fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7337d-e557-46af-b8b1-028ce49554bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "# Compute the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "# Calculate the AUC (Area Under the Curve)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')  # Diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Plot the point at the default threshold of 0.5\n",
    "default_threshold_index = np.where(thresholds > 0.5)[0][-1]\n",
    "plt.plot(fpr[default_threshold_index], tpr[default_threshold_index], 'ro', label='Threshold = 0.5')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ebb82c-f9ef-48cc-90b6-cb6da4ba91e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdc6dc7-7a8d-4d03-88a3-0e50be7981c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f3415f-703c-4eaf-b944-de5b8f970671",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.set_index('id', inplace=True)\n",
    "test.drop(columns=['Driving_License'], inplace=True)\n",
    "test.drop(columns=['Region_Code'], inplace=True)\n",
    "test.drop(columns=['Policy_Sales_Channel'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a50a4f-a3ab-4a66-a7fa-6ffdb7de437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_hat = model.predict(pd.DataFrame(prep.fit_transform(test)), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78abefae-543f-46d1-992f-546bdc55ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(test.reset_index().id).assign(Response=y_hat)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf4032c-ee12-4169-900a-14313d2dc0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f42a3f-78b7-4630-a0fd-f6c0aadcb639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the preprocessing pipeline\n",
    "with open('preprocessing_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(prep, f)\n",
    "    # Save the model in the recommended .keras format\n",
    "model.save('trained_model.keras')\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('trained_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
